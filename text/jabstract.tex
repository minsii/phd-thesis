近年、マルチコアプロセッサが広く普及しているが、消費電力と発熱問題など
の理由により、従来通りの動作周波数向上によるプロセッサ処理性能向上は困
難になっており、コアを増やして更なる並列化により性能を向上するしかない。
インテル社のXeon Phiや、IBM社のBlue Gene/Qなどのメニーコアアーキテク
チャーは数十コア・数百ハードウェアスレッドのような大規模並列環境を提供している。
このようなアーキテクチャーのハードウェアの特徴をまとめると、一つは膨大
なコア数により大規模並列計算環境が提供されていること、もう一つは省エネ
ルギーのために各プロセッサコアの動作周波数が低く抑えされるていることである。
これらの特徴からメニーコアの性能を発揮するには、なるべくアプロケーショ
ン全体を大規模並列化しなければならないが、逆に並列コア数が不足する場合、
性能が悪化することも注意しなければならない。科学計算アプリケーションプロ
グラマーは、大量のコアを有効利用し高性能計算を達成するために様々な計算・通信
プログラミングモデルに注目している。

計算の面から見ると、メモリやその他のシステム資源に比べて大量のコアが提供
されてきている理由から、プロセスとスレッドを混在させるハイブリッドプロ
グラミングモデルに移行している例がある。このようなモデルでは、同一プロセス
に所属する複数スレッドがノード内資源を共有することが可能となる。スレッド
モデルの代表的処理系であるOpenMPと分散メモリシステム上で通信機能を担当
するMPIライブラリの組み合わせがこのモデルの主流である。
ハイブリッドMPI+スレッド型プログラミングが増加しているが、1 MPIプロセ
スが1コア上で走るMPIプロセスだけのプログラミングモデルを採用している
アプリケーションもある。

通信面から見ると、分散メモリシステム上ではメッセージパッシングが通信モ
デルの主流であり、その代表的通信モデルがMPIである。MPIの処理は同期と非同期処理に分けられる。
双方向送受信通信において、メッセージ到着を待つブロッキング送信は同期処
理の一例であり、メッセージ送信の完了を待たずにアプリケーションに処理が
戻るノンブロッキング送信は非同期通信の一例である。
更に、MPI-2規格から定義された片方向通信、いわゆる「Remote Memory
Access、RMA」は、通信の相手の状態に無関係に他のプロセスのデータにアクセ
スできる通信モデルであり、特にInfiniBandやCray Aries、富士通Tofu インタ
コネクトなどのハードウェア片方向通信をサポートするネットワーク上ではよ
り効率的、自然的な非同期処理が実現されている。

アプリケーションの構成の違いにより、最適な計算・通信プログラミングモデ
ルがそれぞれある。しかしながら、メニーコア上でそれらのモデルを効率的に
実行する処理系は未成熟である。
本論文は、科学計算に広く用いられるメッセージパッシング通信モデルを対象
としてメニーコアの特徴を活用して通信性能を最大限に発揮し、あらゆるプロ
グラミングモデルの既存課題を解決して全体性能の向上に貢献する。

まず、ハイブリッドMPI+スレッド型アプリケーションでは、複数のOpenMP
スレッドが計算を並列化してその中の1つがMPI通信を行うという実行モデルが主流である。
このような実行パターンでは、浮動小数点計算を大規模並列化することにより
計算部分の性能向上が達成されるが、通信部分では殆どのスレッドがアイドル
になり、計算資源が無駄になる。また、1つのコアだけが通信処理を担当する
ことにより通信性能の劣化原因ともなる。本論文の第一の貢献は、この問題に
対してアイドル状態になったユーザアプリケーションが作成したスレッドを再
利用して、ユーザ定義データ型通信、共有メモリ通信とネットワークI/O作業
などのMPI内部通信作業を並列化する手法を提案する。本手法により、計算部
分だけでなく、通信を含めてアプリケーション全体がメニーコア資源を利用で
き、全体性能が向上することを示す。

次に、非同期可能な通信処理がたくさんあっても、MPI規格ではこのような通
信が必ず非同期処理されるとは限らない問題点について取り組む。片方向通信
であっても、RMA通信を完了するためにリモート側プロセスがMPIを呼び出さな
いと処理が進まないMPI実装が殆どである。リモート側がMPIを呼び出すまで、
通信処理がローカル側で完了できず、更にリモート側が計算中のためローカル
プロセスが長時間待ちになる恐れもある。既存研究では、バックグラインド
スレッドの手法とシステム割込みに基づく手法が殆どであるが、非効率的な
計算コアの配置、マルチスレッドレベルや頻繁的なシステム割込めが生成した重い
オーバーヘッドなどの欠点が挙げられる。
本論文の第2の貢献として、本課題に対してメニーコアの特徴を活用し、プロセ
スレベルでMPI非同期通信専用コアを実装し、最適な非同期通信処理手法を
提案する。本手法では、ユーザが任意的に計算プロセスに使うコア
数と非同期通信を担当するゴーストプロセスに使うコア数を指定でき、従来の
アプローチよりマルチスレッドレベルやシステム割込みのオーバーヘットを
軽減するとともに、コア配置に対して優れた柔軟性も達成する。
更に、PMPIリダイレクト機能を利用したMPI外部実装方式を採用することにより、
あらゆるMPI実装にも容易にサポートできる利点もある。

この非同期手法を利用して、汎用量子化学計算パッケージNWChemの性能を大幅に
向上でき、特に重要なCCSD(T)シミュレーションに対して30％ほどの性能向上
も達成する。しかしながら、NWChemのような大規模計算プログラムにいつもマルチ
計算段階が含まれ、通信・計算の比率が変わりつつある理由で、この静的非同期
通信の設計は最適とは言えない。例えば、計算が重い段階におけて非同期通
信が必要であるが、通信が重くなると、少数の非同期プロセスを使うことより
多めの計算プロセスを使って通信負荷分散という手法のほうが効率である。本論文の第３
の貢献として、NWChemを実例として各段階の計算・通信性能特徴を深く解析し、
マルチ計算段階に対して動的に非同期通信を自動適応できる機能を提案する。

最後に、非同期通信の他に、MPIプロセスだけで記述されたアプリケーション
に性能を大幅に影響する課題がまだいくつかある。例えば、1MPIプロセスがメッセー
ジを待つ時、メッセージが到着するまでその計算コアはアイドルになり、コア性
能を発揮できなくなる。次の研究計画としては、1コア上でOSプロセスを複数
スケジュールできるユーザレベルプロセスのアプローチに基づき、大量のMPI
プロセスを1コア上で実行して負荷分散やチェックポイントの軽量化などの面から
改良手法を着手する予定である。
