近年、マルチコアプロセッサが広く普及されるが、消費電力と発熱問題などの理由により、
従来の動作周波数の向上によるプロセッサの処理性能向上は困難になっており、比較的に効率
的な方法はコア数を追加して更なる並列化しかない。インテル社のXeon Phiや、IBM社のBlue 
Gene/Qなどのメニーコアアーキテクチャーは我々に数十コア・数百ハードウェアスレッドの
ような大規模並列環境を提供する。このようなアーキテクチャーのハードウェア特徴をまとめると、
一つは膨大なコア数により大規模並列計算環境が提供されることで、もう一つは省エネルギーのために
各プロセッサコアの動作周波数が低く抑えされることである。それらの特徴に従い、メニーコアの
性能を発揮するには、なるべくアプロケーション全体を大規模並列化すべきことがわかるが、逆に並列
コア数が不足の場合、性能が悪化することも注意しないと行けない。メニーコア上で様々な計算・通信
プログラミングモデルに高性能を発揮できるように、科学計算アプリケーションプログラマーはその大
規模並列計算環境の使い方に注目し始まる。

計算の面から見ると、メモリやその他のシステム資源に比べて、プロセッサー数が常により高速に
増加されている等の理由で、アプリケーションがますますプロセスとスレッドを混在させるハイブリッド
プログラミングモデルに移行されている。このようなモデルでは、同一プロセスに所属する複数スレッド
がノード内の資源を共有することが可能となり、スレッドモデルの主役であるOpenMPと分散メモ
リシステム上で通信機能を担当するMPIライブラリの組み合わせが主流となる。一方、ハイブリッド
MPI+スレッド型プログラミングの増加にも関わらず、一MPIプロセスが一コア上で走るMPIプロセス
だけのプログラミングモデルはまだ一部のアプリケーションに使われている。

通信の面から見ると、分散メモリシステム上でメッセージパッシングが通信モデルの主役であり、
MPIが一番使われているその通信モデルの規格となる。MPI処理は、同期と非同期処理に分けられる。
伝統の双方向送受信通信には、メッセージの到着を待つブロッキング送信は同期通信の例であり、
それを待たせずにすぐに返却できるノンブロッキング送信は非同期通信の例として挙げられる。
更に、MPI-2規格から定義された片方向通信、いわゆる「Remote Memory Access、RMA」は、
通信の相手の状態に無関係に他のプロセスのデータにアクセスできる通信モデルであり、特にInfiniBand
やCray Ariesインタコネクトなどのハードウェア片方向通信をサポートするネットワーク上ではより
効率的、自然的な非同期処理を実現できる。

アプリケーションの構成の違いにより、最適な計算・通信プログラミングモデルがそれぞれある。しかし
ながら、メニーコア上でそれらのモデルを効率的に実行するには、まだ困難である。
本論文は、科学計算に広く用いられるメッセージパッシング通信モデルを対象としてメニーコアの特徴を
活用して通信性能を最大限に発揮し、あらゆるプログラミングモデルの既存課題を解決して全体性能の向上に貢献する。


まず、ハイブリッドMPI+スレッド型アプリケーションでは、現在一番使われているハイブ
リッド手法は、複数のOpenMPスレッドが計算を並列化してその中の一つがMPI通信を行うこと
である。このようなパターンでは、浮動小数点計算を大規模並列化することにより計算部分の性能向上が
達成されたが、通信部分では殆どのスレッドがアイドルになり、計算資源の浪費となる。また、一つの軽量
コアだけが通信処理を担当し、全体性能障害の原因ともなる。本論文はこの問題に対して、アイドル状態
になったユーザアプリケーションが作成したスレッドを再利用して、ユーザ定義データ型通信、共有メモリ
通信とネットワークI/O作業などのMPI内部通信作業を並列化する手法を提案する。その手法により、
計算部分だけでなく、通信を含めてアプリケーション全体がメニーコア資源を利用でき、全体性能の向上
を達成する。

次に、MPIプロセスだけ存在するアプリケーションでは、そのようなモデルは大量プロセス間で計算資源の
割合などの問題だけでなく、性能の面でも不利点が色々ある。例えば、一MPIプロセスがメッセージを待つ時、
メッセージが到着するまでその計算コアがアイドルになり性能を発揮できなくなる。本論文は、一コア上で
OSプロセスを複数スケジュールできるユーザレベルプロセスのアプローチに基づき、大量のMPIプロセス
を一コア上で実行して負荷分散やチェックポイントの軽量化などの面から改良手法を提案する。

最後に、通信の非同期処理に関して、非同期可能な通信処理がたくさんあるが、MPI規則ではこのよう
な通信が必ず非同期であることは保証されていない。更に、片方向通信であっても、RMA通信を完成する
ためにリモート側プロセスがMPIを呼び出さないといけないと大分のMPI実装はまだ要求する。従って、
リモート側がMPIを呼び出すまで、通信処理がローカル側で完成できず、更にリモード側が計算中のため
ローカルプロセスが長時間待ちとなる恐れもある。既存研究では、一プロセスが一ヘルプスレッドを生成して
バックグラウンドで受信を処理する手法は殆どであるが、半分の計算コアをヘルプスレッドに使って計算資源
の浪費となる。それに、複数のスレッドが一MPIプロセスの資源にアクセスするため、MPI実装が内部マルチ
スレッドをサポートすると要求される。本論文は、この課題に対して、メニーコアの特徴を活用し、プロセス
レベルのMPI非同期通信専用ヘルプコアの最適化手法を提案する。この手法では、ユーザが任意的に計算プロセ
スに使うコア数とヘルプコア数を指定でき、従来のスレッド型アプローチより優れた柔軟性を達成したとともに、
マルチスレッドレベルのオーバーヘットも軽減する。更に、PMPIリダイレクトを利用したMPI外部実装方式は
あらゆるMPI実装にも容易にサポートできる利点もある。

